{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290ef3f7-806b-4ba2-97aa-a89bc85cb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark azure-storage-blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251480ff-368c-4272-8a8e-e0b5d6890b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the CSV file:\n",
      "['ARREST_KEY', 'ARREST_DATE', 'PD_DESC', 'OFNS_DESC', 'LAW_CODE', 'GENDER', 'ARREST_PRECINCT', 'JURISDICTION_CODE', 'PERP_SEX', 'PERP_RACE', 'X_COORD_CD', 'Y_COORD_CD', 'Latitude', 'Longitude', 'ARREST_YEAR', 'ARREST_MONTH', 'AGE_RANDOM']\n",
      "File 'final_arrest_data_nypd.csv' uploaded to Azure Blob Storage successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Azure Blob Storage connection string\n",
    "azure_blob_connection_string = \"cNvsvKyR7q7rnqcpX1nU32d65m71zwW4AQ6UM5jmnDem/20inTNMBW0LnGan3xV4xTqaUiNfD2Olgr8EkJ12QMmOcFh3zU2UsI6Ylocjzd2xI4+RDGr8g6WlsfviHWD+5M70kE9pC0Gn0TMt4gWhn9pWBrL+TVgXr3HdfAeikCQW2FMuFPtBWphBWgiqp6VQsW9HvObAgYrEN8x+4tFlxc1vD2JsCHn74eqhhh05vzC7Inodp6+R6uzlOqAuJV2B\"\n",
    "\n",
    "# Local file path to upload (use raw string or escape backslashes)\n",
    "local_file_path = r\"D:\\Downloads 2\\George Brown\\Sem 2.5\\Big data 2\\Big Data project\\Files to Submit\\Transformations\\MongoDB_ArrestDataNYPD\\final_arrest_data_nypd.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(local_file_path)\n",
    "\n",
    "# Get the column names from the DataFrame\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the column names\n",
    "print(\"Column names in the CSV file:\")\n",
    "print(column_names)\n",
    "\n",
    "# Blob Storage container name and blob name\n",
    "container_name = \"arrestdatanypd\"  # Replace with your container name\n",
    "blob_name = \"final_arrest_data_nypd.csv\"  # Replace with the name you want to give to your blob/file\n",
    "\n",
    "try:\n",
    "    # Initialize BlobServiceClient using connection string\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(azure_blob_connection_string)\n",
    "\n",
    "    # Create a blob client using the container name and blob name\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "\n",
    "    # Upload a file to Azure Blob Storage\n",
    "    with open(local_file_path, \"rb\") as data:\n",
    "        blob_client.upload_blob(data)\n",
    "\n",
    "    print(f\"File '{blob_name}' uploaded to Azure Blob Storage successfully.\")\n",
    "\n",
    "except Exception as ex:\n",
    "    print(f\"Error uploading file to Azure Blob Storage: {ex}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44294fa-6bb9-4995-af65-551969a92345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94a35a-9359-4235-a290-15303d431fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established successfully!\n",
      "Microsoft SQL Server\n",
      "12.00.5564\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "\n",
    "# Azure SQL Database connection details\n",
    "server = 'blahblah.database.windows.net'\n",
    "database = 'MongoDB_ArrestDataNYPD'\n",
    "username = 'azureuser'\n",
    "password = 'xxxxxxxx'\n",
    "driver = '{ODBC Driver 18 for SQL Server}'\n",
    "\n",
    "# Create the connection string\n",
    "conn_str = (\n",
    "    f'DRIVER={driver};'\n",
    "    f'SERVER={server};'\n",
    "    f'DATABASE={database};'\n",
    "    f'UID={username};'\n",
    "    f'PWD={password};'\n",
    "    f'Encrypt=yes;'\n",
    "    f'TrustServerCertificate=no;'\n",
    "    f'Connection Timeout=30;'\n",
    ")\n",
    "# Adjust the data types according to your actual data\n",
    "columns_with_types = \", \".join([f\"[{col}] VARCHAR(255)\" for col in column_names])\n",
    "\n",
    "# Define the CREATE TABLE statement\n",
    "table_name = \"ArrestDataNYPD\"\n",
    "create_table_sql = f\"CREATE TABLE {table_name} ({columns_with_types});\"\n",
    "\n",
    "try:\n",
    "    # Establish a connection to the Azure SQL Database\n",
    "    connection = pyodbc.connect(conn_str)\n",
    "    \n",
    "    # Print connection details\n",
    "    print(\"Connection established successfully!\")\n",
    "    print(connection.getinfo(pyodbc.SQL_DBMS_NAME))\n",
    "    print(connection.getinfo(pyodbc.SQL_DBMS_VER))\n",
    "\n",
    "    # Execute the CREATE TABLE statement\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(create_table_sql)\n",
    "    connection.commit()\n",
    "\n",
    "except pyodbc.Error as ex:\n",
    "    print(\"Error connecting to Azure SQL Database:\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b761accf-a467-4ff7-aae3-458d2749131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the CSV file:\n",
      "['ARREST_KEY', 'ARREST_DATE', 'PD_DESC', 'OFNS_DESC', 'LAW_CODE', 'GENDER', 'ARREST_PRECINCT', 'JURISDICTION_CODE', 'PERP_SEX', 'PERP_RACE', 'X_COORD_CD', 'Y_COORD_CD', 'Latitude', 'Longitude', 'ARREST_YEAR', 'ARREST_MONTH', 'AGE_RANDOM']\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Azure SQL Database connection details\n",
    "server = 'blahblah.database.windows.net'\n",
    "database = 'MongoDB_ArrestDataNYPD'\n",
    "username = 'azureuser'\n",
    "password = 'Ilove85workWonder69'\n",
    "driver = '{ODBC Driver 18 for SQL Server}'\n",
    "\n",
    "# Create the connection string\n",
    "conn_str = (\n",
    "    f'DRIVER={driver};'\n",
    "    f'SERVER={server};'\n",
    "    f'DATABASE={database};'\n",
    "    f'UID={username};'\n",
    "    f'PWD={password};'\n",
    "    f'Encrypt=yes;'\n",
    "    f'TrustServerCertificate=no;'\n",
    "    f'Connection Timeout=30;'\n",
    ")\n",
    "\n",
    "# Print the column names\n",
    "print(\"Column names in the CSV file:\")\n",
    "print(column_names)\n",
    "# Adjust the data types according to your actual data\n",
    "columns_with_types = \", \".join([f\"[{col}] VARCHAR(255)\" for col in column_names])\n",
    "\n",
    "# Define the CREATE TABLE statement\n",
    "table_name = \"ArrestDataNYPD1\"\n",
    "create_table_sql = f\"CREATE TABLE {table_name} ({columns_with_types});\"\n",
    "# Execute the CREATE TABLE statement\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(create_table_sql)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea97a6d-c3c8-4be9-be5a-14c549442bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303620 entries, 0 to 303619\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   ARREST_KEY         303620 non-null  object\n",
      " 1   ARREST_DATE        303620 non-null  object\n",
      " 2   PD_DESC            303620 non-null  object\n",
      " 3   OFNS_DESC          303620 non-null  object\n",
      " 4   LAW_CODE           303620 non-null  object\n",
      " 5   GENDER             303620 non-null  object\n",
      " 6   ARREST_PRECINCT    303620 non-null  object\n",
      " 7   JURISDICTION_CODE  303620 non-null  object\n",
      " 8   PERP_SEX           303620 non-null  object\n",
      " 9   PERP_RACE          303620 non-null  object\n",
      " 10  X_COORD_CD         303620 non-null  object\n",
      " 11  Y_COORD_CD         303620 non-null  object\n",
      " 12  Latitude           303620 non-null  object\n",
      " 13  Longitude          303620 non-null  object\n",
      " 14  ARREST_YEAR        303620 non-null  object\n",
      " 15  ARREST_MONTH       303620 non-null  object\n",
      " 16  AGE_RANDOM         303620 non-null  object\n",
      "dtypes: object(17)\n",
      "memory usage: 39.4+ MB\n"
     ]
    }
   ],
   "source": [
    "def log_message(message):\n",
    "    \"\"\"Function to log general messages\"\"\"\n",
    "    with open('process_log.txt', 'a') as f:\n",
    "        f.write(message + '\\n')\n",
    "\n",
    "def log_error(error_message):\n",
    "    \"\"\"Function to log errors\"\"\"\n",
    "    with open('error_log.txt', 'a') as f:\n",
    "        f.write(error_message + '\\n')\n",
    "\n",
    "try:\n",
    "    log_message(\"Attempting to establish connection to Azure SQL Database...\")\n",
    "    # Establish a connection to the Azure SQL Database\n",
    "    connection = pyodbc.connect(conn_str)\n",
    "    log_message(\"Connection established successfully!\")\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    log_message(\"Reading CSV file into pandas DataFrame...\")\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    local_file_path = r\"D:\\Downloads 2\\George Brown\\Sem 2.5\\Big data 2\\Big Data project\\Files to Submit\\Transformations\\MongoDB_ArrestDataNYPD\\final_arrest_data_nypd.csv\"\n",
    "    df = pd.read_csv(local_file_path)\n",
    "    log_message(\"CSV file read successfully!\")\n",
    "\n",
    "    # Convert data types if necessary\n",
    "    df = df.astype(str)\n",
    "    log_message(\"Converted DataFrame columns to strings.\")\n",
    "\n",
    "    # Print the DataFrame structure\n",
    "    log_message(f\"DataFrame structure: \\n{df.info()}\")\n",
    "\n",
    "    # Use the entire DataFrame for insertion\n",
    "    df_subset = df\n",
    "    log_message(f\"Using all rows of the DataFrame.\")\n",
    "\n",
    "    # Print the first few rows\n",
    "    log_message(f\"First few rows of the DataFrame subset:\\n{df_subset.head()}\")\n",
    "\n",
    "    # Insert DataFrame records one by one, commit in batches\n",
    "    batch_size = 1000  # Adjust the batch size as needed\n",
    "    batch_values = []\n",
    "\n",
    "    for index, row in df_subset.iterrows():\n",
    "        values = tuple(row)\n",
    "        batch_values.append(values)\n",
    "\n",
    "        if (index + 1) % batch_size == 0 or (index + 1) == len(df_subset):\n",
    "            try:\n",
    "                insert_sql = f\"INSERT INTO ArrestDataNYPD1 VALUES ({', '.join('?' * len(values))})\"\n",
    "                cursor.executemany(insert_sql, batch_values)\n",
    "                connection.commit()\n",
    "                log_message(f\"Committed {index + 1} rows successfully.\")\n",
    "                batch_values.clear()\n",
    "            except pyodbc.Error as e:\n",
    "                error_message = f\"Error inserting batch ending at row {index + 1}: {str(e)}\"\n",
    "                log_error(error_message)\n",
    "                log_message(error_message)\n",
    "                connection.rollback()  # Rollback the batch on error\n",
    "\n",
    "    # Final commit for any remaining rows\n",
    "    if batch_values:\n",
    "        try:\n",
    "            cursor.executemany(insert_sql, batch_values)\n",
    "            connection.commit()\n",
    "            log_message(f\"Committed final batch successfully.\")\n",
    "        except pyodbc.Error as e:\n",
    "            error_message = f\"Error inserting final batch: {str(e)}\"\n",
    "            log_error(error_message)\n",
    "            log_message(error_message)\n",
    "            connection.rollback()  # Rollback the final batch on error\n",
    "\n",
    "    log_message(\"Data inserted successfully into the 'call_data_lapd' table.\")\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    log_message(\"Connection closed successfully.\")\n",
    "\n",
    "except pyodbc.Error as ex:\n",
    "    # Log the connection error to the file\n",
    "    error_message = f\"Error connecting to Azure SQL Database: {str(ex)}\"\n",
    "    log_error(error_message)\n",
    "    log_message(error_message)\n",
    "\n",
    "except Exception as ex:\n",
    "    # Log any other exceptions\n",
    "    error_message = f\"General error: {str(ex)}\"\n",
    "    log_error(error_message)\n",
    "    log_message(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d264df9-5b8c-4a14-9e89-259b39f98a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
