{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290ef3f7-806b-4ba2-97aa-a89bc85cb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark azure-storage-blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251480ff-368c-4272-8a8e-e0b5d6890b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the CSV file:\n",
      "['JOB_ID', 'AGENCY', 'POSTING_TYPE', 'NO_OF_POSITIONS', 'BUSINESS_TITLE', 'CIVIL_SERVICE_TITLE', 'TITLE_CLASSIFICATION', 'TITLE_CODE_NO', 'LEVEL', 'JOB_CATEGORY', 'FULLTIME_OR_PARTTIME_INDICATOR', 'CAREER_LEVEL', 'SALARY_RANGE_FROM', 'SALARY_RANGE_TO', 'SALARY_FREQUENCY', 'WORK_LOCATION', 'DIVISION_OR_WORK_UNIT', 'JOB_DESCRIPTION', 'MINIMUM_QUAL_REQUIREMENTS', 'PREFERRED_SKILLS', 'ADDITIONAL_INFORMATION', 'TO_APPLY', 'HOURS_OR_SHIFT', 'WORK_LOCATION_1', 'RECRUITMENT_CONTACT', 'RESIDENCY_REQUIREMENT', 'POSTING_DATE', 'POST_UNTIL', 'POSTING_UPDATED', 'PROCESS_DATE']\n",
      "File 'job_postings.csv' uploaded to Azure Blob Storage successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Azure Blob Storage connection string\n",
    "azure_blob_connection_string = \"cNvsvKyR7q7rnqcpX1nU32d65m71zwW4AQ6UM5jmnDem/20inTNMBW0LnGan3xV4xTqaUiNfD2Olgr8EkJ12QMmOcFh3zU2UsI6Ylocjzd2xI4+RDGr8g6WlsfviHWD+5M70kE9pC0Gn0TMt4gWhn9pWBrL+TVgXr3HdfAeikCQW2FMuFPtBWphBWgiqp6VQsW9HvObAgYrEN8x+4tFlxc1vD2JsCHn74eqhhh05vzC7Inodp6+R6uzlOqAuJV2B\"\n",
    "\n",
    "# Local file path to upload (use raw string or escape backslashes)\n",
    "local_file_path = r\"C:\\Users\\RC\\Documents\\GBC\\AASD400X_Big_Data_II\\Project\\job_postings.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(local_file_path)\n",
    "\n",
    "# Get the column names from the DataFrame\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the column names\n",
    "print(\"Column names in the CSV file:\")\n",
    "print(column_names)\n",
    "\n",
    "# Blob Storage container name and blob name\n",
    "container_name = \"snowflakejobpostings\"  # Replace with your container name\n",
    "blob_name = \"job_postings.csv\"  # Replace with the name you want to give to your blob/file\n",
    "\n",
    "try:\n",
    "    # Initialize BlobServiceClient using connection string\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(azure_blob_connection_string)\n",
    "\n",
    "    # Create a blob client using the container name and blob name\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "\n",
    "    # Upload a file to Azure Blob Storage\n",
    "    with open(local_file_path, \"rb\") as data:\n",
    "        blob_client.upload_blob(data)\n",
    "\n",
    "    print(f\"File '{blob_name}' uploaded to Azure Blob Storage successfully.\")\n",
    "\n",
    "except Exception as ex:\n",
    "    print(f\"Error uploading file to Azure Blob Storage: {ex}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44294fa-6bb9-4995-af65-551969a92345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da94a35a-9359-4235-a290-15303d431fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established successfully!\n",
      "Microsoft SQL Server\n",
      "12.00.5564\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "\n",
    "# Azure SQL Database connection details\n",
    "server = 'blahblah.database.windows.net'\n",
    "database = 'Snowflake_JobPostingsDataNYPD'\n",
    "username = 'azureuser'\n",
    "password = 'Ilove85workWonder69'\n",
    "driver = '{ODBC Driver 18 for SQL Server}'\n",
    "\n",
    "# Create the connection string\n",
    "conn_str = (\n",
    "    f'DRIVER={driver};'\n",
    "    f'SERVER={server};'\n",
    "    f'DATABASE={database};'\n",
    "    f'UID={username};'\n",
    "    f'PWD={password};'\n",
    "    f'Encrypt=yes;'\n",
    "    f'TrustServerCertificate=no;'\n",
    "    f'Connection Timeout=30;'\n",
    ")\n",
    "# Adjust the data types according to your actual data\n",
    "columns_with_types = \", \".join([f\"[{col}] VARCHAR(255)\" for col in column_names])\n",
    "\n",
    "# Define the CREATE TABLE statement\n",
    "table_name = \"jobpostingstable\"\n",
    "create_table_sql = f\"CREATE TABLE {table_name} ({columns_with_types});\"\n",
    "\n",
    "try:\n",
    "    # Establish a connection to the Azure SQL Database\n",
    "    connection = pyodbc.connect(conn_str)\n",
    "    \n",
    "    # Print connection details\n",
    "    print(\"Connection established successfully!\")\n",
    "    print(connection.getinfo(pyodbc.SQL_DBMS_NAME))\n",
    "    print(connection.getinfo(pyodbc.SQL_DBMS_VER))\n",
    "\n",
    "    # Execute the CREATE TABLE statement\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(create_table_sql)\n",
    "    connection.commit()\n",
    "\n",
    "except pyodbc.Error as ex:\n",
    "    print(\"Error connecting to Azure SQL Database:\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761accf-a467-4ff7-aae3-458d2749131b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea97a6d-c3c8-4be9-be5a-14c549442bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5156 entries, 0 to 5155\n",
      "Data columns (total 30 columns):\n",
      " #   Column                          Non-Null Count  Dtype \n",
      "---  ------                          --------------  ----- \n",
      " 0   JOB_ID                          5156 non-null   object\n",
      " 1   AGENCY                          5156 non-null   object\n",
      " 2   POSTING_TYPE                    5156 non-null   object\n",
      " 3   NO_OF_POSITIONS                 5156 non-null   object\n",
      " 4   BUSINESS_TITLE                  5156 non-null   object\n",
      " 5   CIVIL_SERVICE_TITLE             5156 non-null   object\n",
      " 6   TITLE_CLASSIFICATION            5156 non-null   object\n",
      " 7   TITLE_CODE_NO                   5156 non-null   object\n",
      " 8   LEVEL                           5156 non-null   object\n",
      " 9   JOB_CATEGORY                    5156 non-null   object\n",
      " 10  FULLTIME_OR_PARTTIME_INDICATOR  5156 non-null   object\n",
      " 11  CAREER_LEVEL                    5156 non-null   object\n",
      " 12  SALARY_RANGE_FROM               5156 non-null   object\n",
      " 13  SALARY_RANGE_TO                 5156 non-null   object\n",
      " 14  SALARY_FREQUENCY                5156 non-null   object\n",
      " 15  WORK_LOCATION                   5156 non-null   object\n",
      " 16  DIVISION_OR_WORK_UNIT           5156 non-null   object\n",
      " 17  JOB_DESCRIPTION                 5156 non-null   object\n",
      " 18  MINIMUM_QUAL_REQUIREMENTS       5156 non-null   object\n",
      " 19  PREFERRED_SKILLS                5156 non-null   object\n",
      " 20  ADDITIONAL_INFORMATION          5156 non-null   object\n",
      " 21  TO_APPLY                        5156 non-null   object\n",
      " 22  HOURS_OR_SHIFT                  5156 non-null   object\n",
      " 23  WORK_LOCATION_1                 5156 non-null   object\n",
      " 24  RECRUITMENT_CONTACT             5156 non-null   object\n",
      " 25  RESIDENCY_REQUIREMENT           5156 non-null   object\n",
      " 26  POSTING_DATE                    5156 non-null   object\n",
      " 27  POST_UNTIL                      5156 non-null   object\n",
      " 28  POSTING_UPDATED                 5156 non-null   object\n",
      " 29  PROCESS_DATE                    5156 non-null   object\n",
      "dtypes: object(30)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "def log_message(message):\n",
    "    \"\"\"Function to log general messages\"\"\"\n",
    "    with open('process_log.txt', 'a') as f:\n",
    "        f.write(message + '\\n')\n",
    "\n",
    "def log_error(error_message):\n",
    "    \"\"\"Function to log errors\"\"\"\n",
    "    with open('error_log.txt', 'a') as f:\n",
    "        f.write(error_message + '\\n')\n",
    "\n",
    "try:\n",
    "    log_message(\"Attempting to establish connection to Azure SQL Database...\")\n",
    "    # Establish a connection to the Azure SQL Database\n",
    "    connection = pyodbc.connect(conn_str)\n",
    "    log_message(\"Connection established successfully!\")\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    log_message(\"Reading CSV file into pandas DataFrame...\")\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    local_file_path = r\"C:\\Users\\RC\\Documents\\GBC\\AASD400X_Big_Data_II\\Project\\job_postings.csv\"\n",
    "    df = pd.read_csv(local_file_path)\n",
    "    log_message(\"CSV file read successfully!\")\n",
    "\n",
    "    # Convert data types if necessary\n",
    "    df = df.astype(str)\n",
    "    log_message(\"Converted DataFrame columns to strings.\")\n",
    "\n",
    "    # Print the DataFrame structure\n",
    "    log_message(f\"DataFrame structure: \\n{df.info()}\")\n",
    "\n",
    "    # Use the entire DataFrame for insertion\n",
    "    df_subset = df\n",
    "    log_message(f\"Using all rows of the DataFrame.\")\n",
    "\n",
    "    # Print the first few rows\n",
    "    log_message(f\"First few rows of the DataFrame subset:\\n{df_subset.head()}\")\n",
    "\n",
    "    # Insert DataFrame records one by one, commit in batches\n",
    "    batch_size = 1000  # Adjust the batch size as needed\n",
    "    batch_values = []\n",
    "\n",
    "    for index, row in df_subset.iterrows():\n",
    "        values = tuple(row)\n",
    "        batch_values.append(values)\n",
    "\n",
    "        if (index + 1) % batch_size == 0 or (index + 1) == len(df_subset):\n",
    "            try:\n",
    "                insert_sql = f\"INSERT INTO jobpostingstable VALUES ({', '.join('?' * len(values))})\"\n",
    "                cursor.executemany(insert_sql, batch_values)\n",
    "                connection.commit()\n",
    "                log_message(f\"Committed {index + 1} rows successfully.\")\n",
    "                batch_values.clear()\n",
    "            except pyodbc.Error as e:\n",
    "                error_message = f\"Error inserting batch ending at row {index + 1}: {str(e)}\"\n",
    "                log_error(error_message)\n",
    "                log_message(error_message)\n",
    "                connection.rollback()  # Rollback the batch on error\n",
    "\n",
    "    # Final commit for any remaining rows\n",
    "    if batch_values:\n",
    "        try:\n",
    "            cursor.executemany(insert_sql, batch_values)\n",
    "            connection.commit()\n",
    "            log_message(f\"Committed final batch successfully.\")\n",
    "        except pyodbc.Error as e:\n",
    "            error_message = f\"Error inserting final batch: {str(e)}\"\n",
    "            log_error(error_message)\n",
    "            log_message(error_message)\n",
    "            connection.rollback()  # Rollback the final batch on error\n",
    "\n",
    "    log_message(\"Data inserted successfully into the 'call_data_lapd' table.\")\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    log_message(\"Connection closed successfully.\")\n",
    "\n",
    "except pyodbc.Error as ex:\n",
    "    # Log the connection error to the file\n",
    "    error_message = f\"Error connecting to Azure SQL Database: {str(ex)}\"\n",
    "    log_error(error_message)\n",
    "    log_message(error_message)\n",
    "\n",
    "except Exception as ex:\n",
    "    # Log any other exceptions\n",
    "    error_message = f\"General error: {str(ex)}\"\n",
    "    log_error(error_message)\n",
    "    log_message(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d264df9-5b8c-4a14-9e89-259b39f98a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
